# -*- coding: utf-8 -*-
"""Credit_Scoring

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PRdfRVX7prTFeZv9PW7NiLZty6wVcE-w

# Machine Learning Report Credit Scoring
- **Nama:** Radiga
- **Email:** radiga03@gmail.com
- **ID Dicoding:** radiga_gubarda

##**Domain Project** (Background)

Saat ini industri Perbankan dan Fintech mengalami kemajuan yang pesat seiring dengan kemajuan teknologi. Banyak product yang ditawarkan oleh perbankan dan Fintech seperti Tabungan, Deposito, serta Pinjaman. Pemberian pinjaman kepada individu atau perusahaan memiliki risiko gagal bayar. Rasio kredit NPL di Perbankan di Indonesia hingga Maret 2023 sebesar 2,49% . Hal tersebut membuat bank dan fintech dapat menghadapi kerugian yang tinggi akibat dari gagal bayar. Metode manual dalam menilai Credit Scoring memiliki kelemahan seperti rentan terhadap kesalahan , subjektivitas, dan butuh waktu. Hal tersebut membuat proses credit scoring tidaklah efisien.


Source: https://ojk.go.id/id/kanal/perbankan/data-dan-statistik/laporan-profil-industri-perbankan/Documents/Laporan%20Surveillance%20Perbankan%20Indonesia%20-%20Triwulan%20I%202023.pdf

##**Business Understanding**

###Problem Statement

1. Pemberian pinjaman kepada individu atau perusahaan memiliki risiko gagal bayar yang dapat menimbulkan kerugian bagi bank dan fintech.

2. Metode manual dalam menilai credit scoring rentan terhadap kesalahan, memiliki tingkat subjektivitas yang tinggi, dan memerlukan waktu untuk diproses.

3. Proses penilaian credit scoring manual tidak efisien yang dapat menghambat keputusan pinjaman yang cepat dan akurat.

###Goals

1. Mengurangi Risiko Gagal Bayar: Membuat model prediktif yang dapat membantu perbankan dan fintech mengidentifikasi nasabah dengan risiko gagal bayar rendah, sehingga dapat mengurangi kerugian.

2. Meningkatkan Efisiensi Penilaian Kredit: Mengembangkan sistem berbasis data yang otomatis dan akurat untuk memberikan penilaian credit scoring secara objektif, mengurangi subjektivitas, serta mempercepat proses pengambilan keputusan pinjaman.

3. Mengoptimalkan Pemberian Pinjaman dengan mempertimbangkan berbagai faktor seperti pendapatan, keterlambatan pembayaran, dan riwayat kredit untuk mengurangi tingkat kesalahan dalam penilaian.

###Solution

Menggunakan empat model untuk membandingkan dan memberikan solusi yang terbaik dalam membuat Credit Scoring Predictive yang efektif dan efisien. Adapun model yang digunakan adalah Random Forest, Logistic Regresion, Decision Tree, dan Gradien Boosting. Metrik evaluasi menggunakan Mean Squared Error (MSE) untuk mengukur seberapa besar model salah dalam melakukan predictive sementara R-squared digunakan untuk mengetahui seberapa baik model dalam mengevaluasi pola data.

##**Data Understanding**

Melakukan Data Acquisition Credit Scoring dari Kaggle https://www.kaggle.com/datasets/parisrohan/credit-score-classification/data . Dataset ini memiliki 100.000 data yang terdiri dari 28 Columns. Dataset ini menjelaskan mengenai informasi customers termasuk data-data demografi, payment behaviour, credit score. Tujuan dari project ini adalah membuat sistem yang efektif dalam melakukan prediksi peminjam berdasarkan tiga kategori Good, Standard, dan Poor.

**Dataset**

ID: Unique identifier.

Customer_ID: ID untuk setiap konsumen.

Month: Bulan.

Name: Nama konsumen.

Age: Umur Konsumen.

SSN: Social Security Number of the customer.

Occupation: Pekerjaan konsumen.

Annual_Income: Pendapatan tahunan.

Monthly_Inhand_Salary: Pendapatan bersih setiap bulan.

Num_Bank_Accounts: Jumlah akun bank milik konsumen.

Num_Credit_Card: Jumlah kartu kredit yang dimiliki konsumen.

Interest_Rate: Sukuk bunga.

Num_of_Loan: Jumlah pinjaman konsumen.

Type_of_Loan: Tipe pinjaman konsumen.

Delay_from_due_date: Keterlambatan bayar oleh konsumen.

Num_of_Delayed_Payment: Jumlah dana yang telat dibayar oleh konsumen.

Changed_Credit_Limit: limit karu kredit yang idubah.

Num_Credit_Inquiries: Jumlah permintaan kredit yang dilakukan oleh nasabah.

Credit_Mix: Campuran dari berbagai jenis rekening kredit yang dimiliki oleh nasabah.

Outstanding_Debt: Jumlah Outstanding debt.

Credit_Utilization_Ratio: Rasio kartu kredit yang dapat digunakan.

Credit_History_Age: Umur kartu kredit.

Payment_of_Min_Amount: Minimum pembayaran yang dilakukan.

Total_EMI_per_month: Total Equated Monthly Installment (EMI) yang dibayar oleh konsumen.

Amount_invested_monthly: Jumlah investasi bulanan.

Payment_Behaviour: Cara Bayar Konsumen.

Monthly_Balance: Jumlah saldo bulanan.

Credit_Score: Credit score konsumen.

## Import Semua Packages/Library yang Digunakan
"""

!pip install kaggle

import numpy as np
import pandas as pd
import tensorflow as tf
import zipfile
import os


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OrdinalEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import GradientBoostingRegressor

mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#Get Data set from Kaggle
!kaggle datasets download -d parisrohan/credit-score-classification

# Define the path to the zip file and the directory to extract it to
zip_file_path = "/content/credit-score-classification.zip"
extract_dir = "/content/credit-score"

# Extract the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

df_train = pd.read_csv('/content/credit-score/train.csv')

df_train.info()

df_train

"""###Exploratory Data Analysis (EDA)

Proses menganalisis dataset secara visual dan statistik untuk memahami pola, tren, hubungan, dan anomali sebelum menerapkan model.
"""

df_train.info()

df_train.describe()

df_train.describe(include = 'object').T

"""## Data Preparation

Pada tahap ini akan melakukan cleaning data untuk membuat credit scoring predictive. Tahap pertama menghilangkan column yang tidak dibutuhkan dalam proses pembuatan credit scoring. Tahap kedua mengubah tipe data menjadi numeric agar dapat menghilangkan missing value dan mengubah unique value. Tahap ketiga Mengubah data Credit_Mix, Payment_Behaviour, Credit_Score, dan Occupation menjadi label agar mudah dalam melakukan klasifikasi. Tahap selanjutnya Menentukan korelasi dari setiap hubungan data semakin mendekati satu maka saling terkaitan begitupun sebaliknya. Tahap akhir adalah melakukan split data untuk training dan validation.
"""

df_train.isnull().sum()

df_train.duplicated().sum()

#Menghapus column yang tidak dibutuhkan
df_train.drop(['Customer_ID','Type_of_Loan','ID','Month','SSN','Name', 'Payment_of_Min_Amount'],axis=1,inplace=True)

#Mengubah tipe data dari object menjadi numeric untuk menghilangkan missing value
for i in df_train.columns:
    print(f'{i}:{pd.api.types.infer_dtype(df_train[i])}')

for col in ['Monthly_Inhand_Salary', 'Num_of_Delayed_Payment', 'Num_Credit_Inquiries', 'Amount_invested_monthly', 'Monthly_Balance']:
    df_train[col] = pd.to_numeric(df_train[col], errors='coerce')

for i in df_train.columns:
    print(f'{i}:{pd.api.types.infer_dtype(df_train[i])}')

df_train.dropna(inplace=True)
df_train[['Monthly_Inhand_Salary', 'Num_of_Delayed_Payment', 'Num_Credit_Inquiries', 'Amount_invested_monthly', 'Monthly_Balance']]

df_train['Age'] = pd.to_numeric(df_train['Age'].fillna('0').str.extract('(\d+)')[0], errors='coerce').fillna(0).astype(int)
df_train['Num_of_Loan'] = pd.to_numeric(df_train['Num_of_Loan'].fillna('0').str.extract('(\d+)')[0], errors='coerce').fillna(0).astype(int)
df_train['Annual_Income'] = pd.to_numeric(df_train['Annual_Income'].str.replace(r'[^0-9.]', '', regex=True), errors='coerce')
df_train['Changed_Credit_Limit'] = pd.to_numeric(df_train['Changed_Credit_Limit'].replace('_', np.nan), errors='coerce').fillna(0)
df_train['Outstanding_Debt'] = pd.to_numeric(df_train['Outstanding_Debt'].astype(str).str.replace(r'[^0-9.]', '', regex=True), errors='coerce').fillna(0)
df_train['Occupation'] = df_train['Occupation'].str.replace("_______" , "Other")
df_train = df_train[df_train['Payment_Behaviour'] != '!@9#%8' ]
df_train = df_train[df_train['Credit_Mix'] != '_']

def parse_years_and_months(age):
    if isinstance(age, str):
        years = int(age.split(' Years')[0]) if 'Years' in age else 0
        months = int(age.split('and ')[-1].split(' Months')[0]) if 'Months' in age else 0
        return years * 12 + months
    return 0

df_train['Credit_History_Age_Months'] = df_train['Credit_History_Age'].apply(parse_years_and_months)

df_train.drop(['Credit_History_Age'],axis=1,inplace=True)

df_train.describe(include='object').T

numeric_columns = df_train.select_dtypes(include=['int64', 'float64']).columns

num_columns = 5
num_rows = (len(numeric_columns) + num_columns - 1) // num_columns

fig, axes = plt.subplots(num_rows, num_columns, figsize=(16, 6))

axes = axes.flatten()

for i, column in enumerate(numeric_columns):
    sns.boxplot(x=df_train[column], ax=axes[i])
    axes[i].set_title(column, fontsize=10)
    axes[i].set_xlabel('Value', fontsize=10)
    axes[i].set_ylabel('Count', fontsize=10)

for j in range(len(numeric_columns), num_columns*num_rows):
    axes[j].axis('off')

plt.tight_layout()
plt.show()

"""### Labeling"""

df_train[['Credit_Mix', 'Payment_Behaviour', 'Credit_Score' ,'Occupation']]

categories = ['Bad', 'Standard', 'Good']

encoder = OrdinalEncoder(categories=[categories])

df_train['Credit_Mix_Encoded'] = encoder.fit_transform(df_train[['Credit_Mix']])

categories_payment_behaviour = [
    'Low_spent_Small_value_payments',
    'Low_spent_Medium_value_payments',
    'Low_spent_Large_value_payments',
    'High_spent_Small_value_payments',
    'High_spent_Medium_value_payments',
    'High_spent_Large_value_payments'
]

encoder_payment_behaviour = OrdinalEncoder(categories=[categories_payment_behaviour])

df_train['Payment_Behaviour_Encoded'] = encoder_payment_behaviour.fit_transform(df_train[['Payment_Behaviour']])

categories = ['Poor', 'Standard', 'Good']

encoder = OrdinalEncoder(categories=[categories])

df_train['Credit_Score_Encoded'] = encoder.fit_transform(df_train[['Credit_Score']])

label_encoder = LabelEncoder()
df_train['Occupation_Encoded'] = label_encoder.fit_transform(df_train['Occupation'])

columns_to_drop = [ 'Payment_Behaviour', 'Credit_Mix', 'Occupation','Credit_Score']
df_train.drop(columns=columns_to_drop, inplace=True)

df_train.to_csv("cleaned_dataset.csv", index=False)

df = pd.read_csv("cleaned_dataset.csv")
df.head()

#Menentukan korelasi dari setiap hubungan data semakin mendekati satu maka saling terkaitan begitupun sebaliknya
correlation = df_train.corr()

plt.figure(figsize=(16, 12))
sns.heatmap(correlation , vmax=0.9, square=True, annot=True)
plt.title('Correlation Matrix')
plt.show()

"""#### Split Dataset"""

y = df_train['Credit_Score_Encoded']

X = df_train[['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card',
       'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date',
       'Num_of_Delayed_Payment', 'Changed_Credit_Limit',
       'Num_Credit_Inquiries', 'Outstanding_Debt', 'Credit_Utilization_Ratio',
        'Credit_History_Age_Months', 'Credit_Mix_Encoded', 'Amount_invested_monthly',
       'Occupation_Encoded', 'Monthly_Balance', 'Payment_Behaviour_Encoded']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Modelling

Random Forest Model
"""

model_rf = RandomForestRegressor(n_estimators=200,  random_state=42)
model_rf.fit(X_train, y_train)

y_pred = model_rf.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred)
print("Random Forest Mean Squared Error:", mse_rf)

r2_rf = r2_score(y_test, y_pred)
print("Random Forest R-squared:", r2_rf)

"""Logistic Regression"""

model_lr = LogisticRegression(penalty='l1', solver='liblinear')

model_lr.fit(X_train, y_train)

y_pred = model_lr.predict(X_test)
mse_lr = mean_squared_error(y_test, y_pred)
print("Logistic Regression Mean Squared Error:", mse_lr)

r2_lr = r2_score(y_test, y_pred)
print("Logistic Regression R-squared:", r2_lr)

"""Decision Tree"""

tree_model = DecisionTreeRegressor(random_state=42)

tree_model.fit(X_train, y_train)

y_pred_tree = tree_model.predict(X_test)

mse_tree = mean_squared_error(y_test, y_pred_tree)
r2_tree = r2_score(y_test, y_pred_tree)

print(f"Decision Tree MSE: {mse_tree}")
print(f"Decision Tree R-squared: {r2_tree}")

"""Gradient Boosting"""

gbr_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

gbr_model.fit(X_train, y_train)

y_pred_gbr = gbr_model.predict(X_test)

mse_gbr = mean_squared_error(y_test, y_pred_gbr)
r2_gbr = r2_score(y_test, y_pred_gbr)

print(f"Gradient Boosting MSE: {mse_gbr}")
print(f"Gradient Boosting R-squared: {r2_gbr}")

"""## Evaluasi dan Visualisasi"""

models = ['Random Forest', 'Logistic Regression', 'Decision Tree', 'Gradient Boosting']
mse_values = [mse_rf, mse_lr, mse_tree, mse_gbr]
r2_values = [r2_rf, r2_lr, r2_tree, r2_gbr]

# MSE
plt.figure(figsize=(10, 5))
plt.bar(models, mse_values)
plt.title('Mean Squared Error (MSE)')
plt.xlabel('Models')
plt.ylabel('MSE')
plt.show()

# R-squared
plt.figure(figsize=(10, 5))
plt.bar(models, r2_values)
plt.title('R-squared')
plt.xlabel('Models')
plt.ylabel('R-squared')
plt.show()

"""**Kesimpulan**


---

Dari hasil yang didapat, Model Random Forest dengan Mean Squared Error (MSE) sebesar 0.2027 dan R-squared sebesar 0.5545, menunjukkan bahwa model ini memiliki tingkat kesalahan yang relatif rendah dibandingkan dengan model lainnya. Sebaliknya, Logistic Regression memiliki performa paling rendah dengan MSE sebesar 0.4873 dan R-squared negatif sebesar -0.0711.

Decision Tree memiliki MSE sebesar 0.3966 dan R-squared sebesar 0.1281 menunjukkan performa yang lebih baik daripada Logistic Regression, tapi masih jauh dari Random Forest. Sementara Gradient Boosting memiliki hasil yang baik dengan MSE sebesar 0.2602 dan R-squared sebesar 0.4280, meski masih di bawah Random Forest.

Dapat disimpulkan bahwa Random Forest adalah model terbaik untuk credit scoring berdasarkan hasil MSE dan R-squared, diikuti oleh Gradient Boosting, sedangkan Logistic Regression adalah yang paling tidak efektif.
"""